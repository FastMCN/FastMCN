{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "planned-crest",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-advocacy",
   "metadata": {},
   "source": [
    "# Explanation for line 332 to 335\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "f & = Index_{row}(F, I^c) \\\\\n",
    "Q & = (f + P) \\cdot W^Q \\\\\n",
    "& = f \\cdot W^Q + P \\cdot W^Q \\\\\n",
    "& = Index_{row}(F, I^c) \\cdot W^Q + P \\cdot W^Q \\\\\n",
    "& = Index_{row}(F \\cdot W^Q, I^c) + P \\cdot W^Q\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acute-exhibition",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "executive-retirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "## n is the size of character set.\n",
    "n = 64\n",
    "\n",
    "## d_emb denotes the embedding dimension.\n",
    "d_emb = 512\n",
    "\n",
    "## F denotes the all embeddings in the character embedding layer.\n",
    "## F shape: (n, d_emb)\n",
    "character_embedding_layer = torch.nn.Embedding(n, d_emb, padding_idx=0).to(device)\n",
    "F = character_embedding_layer.weight\n",
    "\n",
    "def generate_position_embeddings(max_length, d_emb):\n",
    "    \"\"\"Generate position embeddings, according to the method mentioned in\n",
    "\"Attention is all you need\", from Vaswani et al\"\"\"\n",
    "    d_emb_half = d_emb >> 1\n",
    "    frequencies = torch.pow(torch.tensor([1e4]), -1 / d_emb_half).repeat([d_emb_half])\n",
    "    frequencies[0] = 1.0\n",
    "    frequencies = frequencies.cumprod(-1)\n",
    "    positions = torch.arange(0, max_length)\n",
    "    phases = torch.einsum(\"i, j->ij\", positions, frequencies)\n",
    "    position_embeddings = torch.zeros([max_length, d_emb])\n",
    "    position_embeddings[:, 0::2] = torch.sin(phases)\n",
    "    position_embeddings[:, 1::2] = torch.cos(phases)\n",
    "    return position_embeddings\n",
    "\n",
    "## l is the max length of the words\n",
    "l = 32\n",
    "\n",
    "## P denotes the all position embeddings.\n",
    "## P shape: (l, d_emb)\n",
    "P = generate_position_embeddings(l, d_emb).to(device)\n",
    "\n",
    "## IC is the character index for words. \n",
    "## Here, we randomly sample 500x32 integers from 0 to 63 as the index,\n",
    "## which means that there are 500 words, and the maximum length of word is 32 characters.\n",
    "## In practice, we will generate the index according to the character sequence of the word, \n",
    "## and fill 0 to fit the maximum length. \n",
    "## For example, if maximum length of word is 8, the word \"apple\" will be encoded as\n",
    "## [1, 16, 16, 12, 5, 0, 0, 0]. (a: 1, p: 16, l: 12, e: 5)\n",
    "## IC shape: [500, 32]\n",
    "IC = torch.randint(low=0, high=64, size=[500, 32]).to(device)\n",
    "\n",
    "## WQ, WK, WV is the weight matrix for calculating Q, K, V.\n",
    "WQ = torch.nn.Linear(in_features=d_emb, out_features=d_emb, bias=False).to(device)\n",
    "WK = torch.nn.Linear(in_features=d_emb, out_features=d_emb, bias=False).to(device)\n",
    "WV = torch.nn.Linear(in_features=d_emb, out_features=d_emb, bias=False).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-intention",
   "metadata": {},
   "source": [
    "## Index at first, then dot product\n",
    "\n",
    "\\begin{align*}\n",
    "f & = Index_{row}(F, I^c) \\\\\n",
    "Q & = (f + P) \\cdot W^Q\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "moving-grant",
   "metadata": {},
   "outputs": [],
   "source": [
    "## character_embedding_layer(IC) means Index_row(F, I^C)\n",
    "## f shape: (500, l, d_emb)\n",
    "f = character_embedding_layer(IC)\n",
    "\n",
    "## WQ(f + P) means (f + P) \\cdot W^Q\n",
    "## Q_index_at_first shape: (500, l, d_emb)\n",
    "Q_index_at_first = WQ(f + P.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-sewing",
   "metadata": {},
   "source": [
    "## Dot product at first, then index\n",
    "\n",
    "\\begin{align}\n",
    "Meta^Q & = F \\cdot W^Q \\\\\n",
    "Pos^Q & = P \\cdot W^Q \\\\\n",
    "Q & = Index_{row}(Meta^Q, I^c) + Pos^Q\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "serial-system",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index(matrix, index, dim):\n",
    "    shape_head = matrix.shape[:dim]\n",
    "    shape_tail = list(matrix.shape[dim:])\n",
    "    shape_tail.pop(0)\n",
    "    new_shape = [*shape_head, *index.shape, *shape_tail]\n",
    "    return matrix.index_select(dim, index.reshape(-1)).reshape(new_shape)\n",
    "\n",
    "## WQ(F) means F \\cdot W^Q\n",
    "## metaQ shape: (n, d_emb)\n",
    "metaQ = WQ(F)\n",
    "\n",
    "## WQ(P) means P \\cdot W^Q\n",
    "## posQ shape: (l, d_emb)\n",
    "posQ = WQ(P)\n",
    "\n",
    "## Q_dot_product_at_first shape: (500, l, d_emb)\n",
    "Q_dot_product_at_first = index(metaQ, IC, -2) + posQ.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-hurricane",
   "metadata": {},
   "source": [
    "## The mean absolute error(MAE) between two method\n",
    "\n",
    "The MAE is about $2.2\\times10^{-7}$, mean that the results of the two methods are almost equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "surrounded-dispute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.195932609083684e-07\n"
     ]
    }
   ],
   "source": [
    "mae = torch.mean(torch.abs(Q_index_at_first - Q_dot_product_at_first))\n",
    "print(mae.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-macedonia",
   "metadata": {},
   "source": [
    "## Efficiency comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "quick-plane",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index at first costs 11.20 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "for i in range(10000):\n",
    "    f = character_embedding_layer(IC)\n",
    "    Q_index_at_first = WQ(f + P.unsqueeze(0))\n",
    "    \n",
    "wall_time_index_at_first = time() - start\n",
    "print(f\"Index at first costs {wall_time_index_at_first:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fallen-narrow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot product at first costs 4.38 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "for i in range(10000):\n",
    "    metaQ = WQ(F)\n",
    "    posQ = WQ(P)\n",
    "    Q_dot_product_at_first = index(metaQ, IC, -2) + posQ.unsqueeze(0)\n",
    "    \n",
    "wall_time_dot_product_at_first = time() - start\n",
    "print(f\"Dot product at first costs {wall_time_dot_product_at_first:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-absorption",
   "metadata": {},
   "source": [
    "# Explanation for index based scale dot-product attention(ISDPA, Page 5, Algorithm 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-geneva",
   "metadata": {},
   "source": [
    "## Scale dot-product attention (SDPA)\n",
    "\n",
    "$$Attention(Q, K, V) = softmax\\left(\\frac{QK^T}{\\sqrt{d_{emb}}}\\right)V$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-carry",
   "metadata": {},
   "source": [
    "## $QK^T$ can be computed by index\n",
    "\n",
    "\\begin{align}\n",
    "f & = Index_{row}(F, I^c) \\\\\n",
    "Q & = (f + P) \\cdot W^Q   \\\\\n",
    "K & = (f + P) \\cdot W^K   \\\\\n",
    "Meta^Q & = F \\cdot W^Q    \\\\\n",
    "Meta^K & = F \\cdot W^K    \\\\\n",
    "Pos^Q & = P \\cdot W^Q     \\\\\n",
    "Pos^K & = P \\cdot W^K     \\\\\n",
    "% Mm & = (Meta^Q)(Meta^K)^T \\\\\n",
    "% Mp & = (Meta^Q)(Pos^K)^T  \\\\\n",
    "% Pm & = (Pos^Q)(Meta^K)^T  \\\\\n",
    "% Pp & = (Pos^Q)(Pos^K)^T   \\\\\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "QK^T & = ((f + P) \\cdot W^Q)((f + P) \\cdot W^K)^T \\\\\n",
    "& = (f \\cdot W^Q + P \\cdot W^Q)(f \\cdot W^K + P \\cdot W^K)^T \\\\\n",
    "& = (f \\cdot W^Q)(f \\cdot W^K)^T + (f \\cdot W^Q)(P \\cdot W^K)^T + \\\\\n",
    "& \\ \\ \\ \\ \\ (P \\cdot W^Q)(f \\cdot W^K)^T + (P \\cdot W^Q)(P \\cdot W^K)^T \\\\\n",
    "& = (f \\cdot W^Q)(f \\cdot W^K)^T + (f \\cdot W^Q)(P \\cdot W^K)^T + \\\\\n",
    "& \\ \\ \\ \\ \\ (P \\cdot W^Q)(f \\cdot W^K)^T + (P \\cdot W^Q)(P \\cdot W^K)^T \\\\\n",
    "& = (Index_{row}(F, I^c) \\cdot W^Q)(Index_{row}(F, I^c) \\cdot W^K)^T + \\\\\n",
    "& \\ \\ \\ \\ \\ (Index_{row}(F, I^c) \\cdot W^Q)(P \\cdot W^K)^T + \\\\\n",
    "& \\ \\ \\ \\ \\ (P \\cdot W^Q)(Index_{row}(F, I^c) \\cdot W^K)^T + \\\\\n",
    "& \\ \\ \\ \\ \\ (P \\cdot W^Q)(P \\cdot W^K)^T \\\\\n",
    "& = (Index_{row}(F \\cdot W^Q, I^c))(Index_{row}(F \\cdot W^K, I^c))^T + \\\\\n",
    "& \\ \\ \\ \\ \\ (Index_{row}(F \\cdot W^Q, I^c))(P \\cdot W^K)^T + \\\\\n",
    "& \\ \\ \\ \\ \\ (P \\cdot W^Q)(Index_{row}(F \\cdot W^K, I^c))^T + \\\\\n",
    "& \\ \\ \\ \\ \\ (P \\cdot W^Q)(P \\cdot W^K)^T \\\\\n",
    "& = Index_{column}(Index_{row}((F \\cdot W^Q)(F \\cdot W^K)^T, I^c), I^c) + \\\\\n",
    "& \\ \\ \\ \\ \\ Index_{row}((F \\cdot W^Q)(P \\cdot W^K)^T, I^c) + \\\\\n",
    "& \\ \\ \\ \\ \\ Index_{column}((P \\cdot W^Q)(F \\cdot W^K)^T, I^c) + \\\\\n",
    "& \\ \\ \\ \\ \\ (P \\cdot W^Q)(P \\cdot W^K)^T \\\\\n",
    "& = Index_{column}(Index_{row}((Meta^Q)(Meta^K)^T, I^c), I^c) + \\\\\n",
    "& \\ \\ \\ \\ \\ Index_{row}((Meta^Q)(Pos^K)^T, I^c) + \\\\\n",
    "& \\ \\ \\ \\ \\ Index_{column}((Pos^Q)(Meta^K)^T, I^c) + \\\\\n",
    "& \\ \\ \\ \\ \\ (Pos^Q)(Pos^K)^T \\\\\n",
    "% & = Index_{column}(Index_{row}(Mm, I^c), I^c) + Index_{row}((Mp, I^c) + \\\\\n",
    "% & \\ \\ \\ \\ \\ Index_{column}(Pm, I^c) + Pp^T \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-access",
   "metadata": {},
   "source": [
    "### Compute Q, K, V by standard method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fantastic-atlantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_qkv_by_standard_method(P, IC):\n",
    "    \"\"\"P denotes the all position embeddings.\n",
    "IC is the character index for words.\"\"\"\n",
    "    ## character_embedding_layer(IC) means Index_row(F, I^C)\n",
    "    ## f shape: (500, l, d_emb)\n",
    "    f = character_embedding_layer(IC)\n",
    "\n",
    "    ## WQ(f + P) means (f + P) \\cdot W^Q\n",
    "    ## Q shape: (500, l, d_emb)\n",
    "    Q = WQ(f + P)\n",
    "\n",
    "    ## WK(f + P) means (f + P) \\cdot W^Q\n",
    "    ## K shape: (500, l, d_emb)\n",
    "    K = WK(f + P)\n",
    "\n",
    "    ## WK(f + P) means (f + P) \\cdot W^Q\n",
    "    ## K shape: (500, l, d_emb)\n",
    "    V = WV(f + P)\n",
    "    \n",
    "    ## QK^T\n",
    "    ## QK shape: (500, l, l)\n",
    "    QK_standard = Q @ K.transpose(-1, -2)\n",
    "    return V, QK_standard\n",
    "\n",
    "\n",
    "V, QK_standard = compute_qkv_by_standard_method(P, IC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-operator",
   "metadata": {},
   "source": [
    "### Compute Q, K, V by index method\n",
    "\n",
    "The following statements correspond to line 410 to 417 of the manuscript. As an explanation, W_P^Q, W_P^K, W_P^V are equal to W_M^Q, W_M^Q, W_M^V respectively. This can help us to confirm whether computing QK by index method can achive the same result as the standard method. But in fact, for performance considerations, we actually use different weight matrixes to compute posQ, posK, posV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "greenhouse-laundry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_qkv_by_index_method(F, P, IC):\n",
    "    \"\"\"F denotes the all embeddings in the character embedding layer.\n",
    "P denotes the all position embeddings.\n",
    "IC is the character index for words.\"\"\"\n",
    "    ## WQ(F) means F \\cdot W_M^Q\n",
    "    ## metaQ shape: (n, d_emb)\n",
    "    metaQ = WQ(F)\n",
    "\n",
    "    ## WK(F) means F \\cdot W_M^Q\n",
    "    ## metaK shape: (n, d_emb)\n",
    "    metaK = WK(F)\n",
    "\n",
    "    ## WV(F) means F \\cdot W_M^V\n",
    "    ## metaV shape: (n, d_emb)\n",
    "    metaV = WV(F)\n",
    "\n",
    "    ## As an explanation, W_P^Q, W_P^K, W_P^V are equal to W_M^Q, W_M^Q, W_M^V respectively.\n",
    "    ## This can help us to confirm whether computing QK by index method can achive the same result as the standard method.\n",
    "    ## But in fact, for performance considerations, we actually use different weight matrixes to compute posQ, posK, posV\n",
    "    ## WQ(P) means P \\cdot W_P^Q\n",
    "    ## posQ shape: (l, d_emb)\n",
    "    posQ = WQ(P)\n",
    "\n",
    "    ## WK(P) means P \\cdot W_P^K\n",
    "    ## posK shape: (l, d_emb)\n",
    "    posK = WK(P)\n",
    "\n",
    "    ## WV(P) means P \\cdot W_P^V\n",
    "    ## posK shape: (l, d_emb)\n",
    "    posV = WV(P)\n",
    "\n",
    "    ## Compute V\n",
    "    V = index(metaV, IC, -2) + posV\n",
    "    \n",
    "    ## Mm = Index_{column}(Index_{row}((Meta^Q)(Meta^K)^T, I^c), I^c)\n",
    "    ## mm shape: (500, l, l)\n",
    "    mm = metaQ @ metaK.transpose(-1, -2)\n",
    "    # mm = mm.unsqueeze(0)\n",
    "    # mm = torch.cat([mm.index_select(-2, i).index_select(-1, i) for i in IC])\n",
    "    mm = index(mm, IC, -2)\n",
    "    column_indexes = torch.einsum(\n",
    "        \"wac, wbc -> wabc\",\n",
    "        torch.stack((IC, torch.ones_like(IC)), -1),\n",
    "        torch.stack((torch.ones_like(IC), IC), -1))\n",
    "    mm = mm.gather(-1, column_indexes[:, :, :, 1])\n",
    "\n",
    "    ## Mp = Index_{row}((Meta^Q)(Pos^K)^T, I^c)\n",
    "    ## mp shape: (500, l, l)\n",
    "    mp = metaQ @ posK.transpose(-1, -2)\n",
    "    mp = index(mp, IC, -2)\n",
    "\n",
    "    ## Pm = Index_{column}((Pos^Q)(Meta^K)^T, I^c)\n",
    "    ## pm shape: (500, l, l)\n",
    "    pm = posQ @ metaK.transpose(-1, -2)\n",
    "    pm = index(pm, IC, -1).transpose(0, 1)\n",
    "\n",
    "    ## Pp = (Pos^Q)(Pos^K)^T\n",
    "    ## pp shape: (1, l, l)\n",
    "    pp = posQ @ posK.transpose(-1, -2)\n",
    "    \n",
    "    ## QK shape: (500, l, l)\n",
    "    QK_index = mm + mp + pm + pp\n",
    "    return V, QK_index\n",
    "\n",
    "\n",
    "V, QK_index = compute_qkv_by_index_method(F, P, IC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-movement",
   "metadata": {},
   "source": [
    "### The mean absolute error(MAE) between two method\n",
    "\n",
    "The MAE is about $6.4\\times10^{-6}$, mean that the results of the two methods are almost equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "brave-authority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.423888862627791e-06\n"
     ]
    }
   ],
   "source": [
    "mae = torch.mean(torch.abs(QK_standard - QK_index))\n",
    "print(mae.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-spouse",
   "metadata": {},
   "source": [
    "### Efficiency comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "allied-justice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standard method costs 36.69 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "for i in range(10000):\n",
    "    V, QK_standard = compute_qkv_by_standard_method(P, IC)\n",
    "    \n",
    "wall_time_standard = time() - start\n",
    "print(f\"The standard method costs {wall_time_standard:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "corrected-accent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index method costs costs 7.28 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "for i in range(10000):\n",
    "    V, QK_index = compute_qkv_by_index_method(F, P, IC)\n",
    "\n",
    "wall_time_index = time() - start\n",
    "print(f\"The index method costs costs {wall_time_index:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-poland",
   "metadata": {},
   "source": [
    "## The whole process of ISDPA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "tamil-installation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isdpa(F, P, IC):\n",
    "    \"\"\"ISDPA: Index based scale dot-product attention.\n",
    "F denotes the all embeddings in the character embedding layer.\n",
    "P denotes the all position embeddings.\n",
    "IC is the character index for words.\"\"\"\n",
    "    ## Compute QK^T\n",
    "    V, QK_index = compute_qkv_by_index_method(F, P, IC)\n",
    "\n",
    "    ## The self attention matrix\n",
    "    score = torch.softmax(QK_index / torch.sqrt(torch.tensor(d_emb).float()), -1)\n",
    "\n",
    "    ## Calculate the means of Score by columns as mean pooling.\n",
    "    score = score.mean(-2)\n",
    "\n",
    "    ## Compute the result\n",
    "    result = torch.einsum(\"wl, wld -> wd\", score, V)\n",
    "    return result  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "polar-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdpa(P, IC):\n",
    "    \"\"\"SDPA: Scale dot-product attention.\n",
    "P denotes the all position embeddings.\n",
    "IC is the character index for words.\"\"\"    \n",
    "    ## Compute QK^T\n",
    "    V, QK_standard = compute_qkv_by_standard_method(P, IC)\n",
    "\n",
    "    ## The self attention matrix\n",
    "    score = torch.softmax(QK_standard / torch.sqrt(torch.tensor(d_emb).float()), -1)\n",
    "\n",
    "    ## Calculate the means of Score by columns as mean pooling.\n",
    "    score = score.mean(-2)\n",
    "\n",
    "    ## Compute the result\n",
    "    result = torch.einsum(\"wl, wld -> wd\", score, V)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-interaction",
   "metadata": {},
   "source": [
    "### The mean absolute error(MAE) between two method\n",
    "\n",
    "The MAE is about $6.4\\times10^{-6}$, mean that the results of the two methods are almost equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "appreciated-joyce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.423888862627791e-06\n"
     ]
    }
   ],
   "source": [
    "torch.mean(torch.abs(isdpa(F, P, IC) - sdpa(P, IC)))\n",
    "print(mae.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-bahrain",
   "metadata": {},
   "source": [
    "### Efficiency comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "square-punch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SDPA costs 38.63 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "for i in range(10000):\n",
    "    result = sdpa(P, IC)\n",
    "    \n",
    "wall_time_sdpa = time() - start\n",
    "print(f\"The SDPA costs {wall_time_sdpa:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "blank-mobile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ISDPA costs 8.88 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "for i in range(10000):\n",
    "    result = isdpa(F, P, IC)\n",
    "    \n",
    "wall_time_isdpa = time() - start\n",
    "print(f\"The ISDPA costs {wall_time_isdpa:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-logistics",
   "metadata": {},
   "source": [
    "# Explanation for \"2-D stack for multi-head attentions\"(Page 4, line 365-385)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "crude-commercial",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Suposed head_1, head_2, ..., head_h have been computed.\n",
    "## h denotes for the number of heads.\n",
    "h = 32\n",
    "heads = [torch.rand([500, d_emb]).to(device) for i in range(h)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-abraham",
   "metadata": {},
   "source": [
    "## Standard multi-head attention\n",
    "\n",
    "\\begin{align}\n",
    "MultiHead(Q, K, V) & = Concat(head_1, ... ,head_h)W^O \\\\\n",
    "where \\ head_i & = SDPA(Q_i, K_i, V_i) \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aquatic-conversion",
   "metadata": {},
   "outputs": [],
   "source": [
    "WO_multi_head = torch.nn.Linear(h * d_emb, d_emb, bias=False).to(device)\n",
    "\n",
    "def multi_head(heads):\n",
    "    ## After concat, multi_head is a 2-D tensor.\n",
    "    ## multi_head shape: (500, d_emb * h)\n",
    "    heads = torch.cat(heads, dim=-1)\n",
    "    ## multi_head_result shape: (500, d_emb)\n",
    "    multi_head_result = WO_multi_head(heads)\n",
    "    return multi_head_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-affect",
   "metadata": {},
   "source": [
    "## 2-D stack for multi-head attentions\n",
    "\n",
    "\\begin{align*}\n",
    "  MultiHead(Q, K, V) & = Tanh(Tanh(Stack(head_1, head_2, \\cdots, head_h)W^H)W^O) \\\\\n",
    "  \\text{where} \\ head_i & = ISDPA(Q_i, K_i, V_i)\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "running-builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "## n_hidden: the number of MLP hidden nodes.\n",
    "n_hidden = 16\n",
    "\n",
    "## n_output: the number of MLP output nodes\n",
    "n_output = 1\n",
    "\n",
    "WH_stack_multi_head = torch.nn.Linear(h, n_hidden, bias=False).to(device)\n",
    "WO_stack_multi_head = torch.nn.Linear(n_hidden, n_output, bias=False).to(device)\n",
    "\n",
    "def stack_multi_head(heads):\n",
    "    ## After stack, multi_head is a 3-D tensor. For each word, multi_head is a 2-D tensor.\n",
    "    ## multi_head shape: (500, d_emb, h)\n",
    "    heads = torch.stack(heads, dim=-1)\n",
    "    multi_head_result = torch.tanh(WH_stack_multi_head(heads))\n",
    "    ## multi_head_result shape: (500, d_emb * n_output)\n",
    "    multi_head_result = torch.tanh(WO_stack_multi_head(multi_head_result)).reshape([500, d_emb * n_output])\n",
    "    return multi_head_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
